from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from langchain.prompts import PromptTemplate
from langchain_openai import OpenAI
from langchain.chains import LLMChain
import os
import json
from dotenv import load_dotenv

# Load .env file for OpenAI API key
load_dotenv()
llm = OpenAI(temperature=0.7, openai_api_key=os.getenv("OPENAI_API_KEY"))

# Load emoji2emotion.json
with open("emoji2emotion_filtered_baseintensity.json", "r", encoding="utf-8") as f:
    emoji_emotion_data = json.load(f)

# Initialize FastAPI app
app = FastAPI()

# Define request and response models
class EmotionRequest(BaseModel):
    emoji: str  # e.g., "ğŸ˜­", "ğŸ˜„"

class FoodRecommendation(BaseModel):
    food: str
    reason: str

class RecommendationResponse(BaseModel):
    emotion: str
    intensity: float
    recommendations: list[FoodRecommendation]

# Define prompt template with friendly tone and intensity-based nuance
prompt_template = PromptTemplate.from_template(
    """
    ë„ˆëŠ” ê°ì •ì— ë”°ë¼ ìŒì‹ì„ ì¶”ì²œí•´ì£¼ëŠ” ì¹œêµ¬ì•¼.
    5ë…„ ì´ìƒ ëœ ì¹œêµ¬ì²˜ëŸ¼ ëŒ€í™”ì²´ë¡œ ëŒ€í™”í•´ì¤˜. ë‹¨ë‹µí˜• ëŒ€ë‹µì€ ì ˆëŒ€ í•˜ì§€ë§ˆ.
    ì‚¬ìš©ìê°€ ë³´ë‚¸ ì´ëª¨ì§€ì— ë”°ë¼ ê°ì •ì„ ì½ì–´ë‚´ê³ , ê·¸ ê°ì •ì˜ ê°•ë„ì— ë”°ë¼ ì¶”ì²œí•˜ëŠ” ìŒì‹ì„ ë‹¬ë¦¬í•´ì¤˜.
    
    ì§€ê¸ˆ ì‚¬ìš©ìëŠ” {emotion}í•œ ê¸°ë¶„ì´ê³ , ê·¸ ê°•ë„ëŠ” {intensity} ì •ë„ì•¼ (0ì—ì„œ 1 ì‚¬ì´).
    ê°ì •ì´ ê°•í• ìˆ˜ë¡ ì§„ì‹¬ì„ ë‹´ê³  ìœ„ë¡œí•˜ë“¯ì´, ê°ì •ì´ ì•½í•˜ë©´ ê°€ë³ê³  ìœ ì¾Œí•˜ê²Œ ë§í•´ì¤˜.
    ì–´ìš¸ë¦´ë§Œí•œ ìŒì‹ 3ê°€ì§€ë¥¼ ì¶”ì²œí•´ì£¼ê³ , ê° ìŒì‹ì— ëŒ€í•´ í•œ ë¬¸ì¥ ì •ë„ë¡œ ê°„ë‹¨í•œ ì´ìœ ë„ ë§ë¶™ì—¬ì¤˜.
    ì´ìœ ëŠ” ìµœì†Œ 15ì ì´ìƒ, ìµœëŒ€ 30ì ì´ë‚´ë¡œ í•´ì¤˜.
    ì¶”ì²œí•˜ëŠ” ìŒì‹ì€ í•œêµ­ì—ì„œ ìì£¼ ë¨¹ëŠ” ìŒì‹ìœ¼ë¡œë§Œ í•´ì¤˜.
    
    ì˜ˆë¥¼ ë“¤ë©´ í•œì‹, ì–‘ì‹, ëŒ€ì¤‘í™”ëœ ì¼ì‹, ëŒ€ì¤‘í™”ëœ ì¤‘ì‹, ë°°ë‹¬ìŒì‹ ê°™ì€ ì‹¤ì œ ì‚¬ëŒë“¤ì´ ìì£¼ ë¨¹ëŠ” ìŒì‹ë“¤ë¡œë§Œ ì¶”ì²œí•´. 
    íŠ¹ì´í•˜ê±°ë‚˜ ì™¸êµ­ ìŒì‹, ìƒì†Œí•œ ìš”ë¦¬ëŠ” ì ˆëŒ€ ì¶”ì²œí•˜ì§€ ë§ˆ.
    í˜•ì‹:
    1. ìŒì‹ - ì´ìœ 
    2. ìŒì‹ - ì´ìœ 
    3. ìŒì‹ - ì´ìœ 
    """
)

# Create the LLM chain
chain = LLMChain(llm=llm, prompt=prompt_template)

# Define API endpoint
@app.post("/gpt/recommendation", response_model=RecommendationResponse)
async def get_recommendation(request: EmotionRequest):
    try:
        # Extract emotion and intensity from emoji
        data = emoji_emotion_data.get(request.emoji)
        if not data:
            raise HTTPException(status_code=400, detail="Unsupported emoji")

        emotion = data["emotion"]
        intensity = data["intensity"]

        # Call GPT chain with emotion and intensity
        result = chain.run({"emotion": emotion, "intensity": intensity})

        # Parse GPT result
        lines = [line.strip() for line in result.split("\n") if line.strip()]
        recommendations = []
        for line in lines:
            if "." in line and "-" in line:
                try:
                    _, rest = line.split(".", 1)
                    food, reason = rest.split("-", 1)
                    recommendations.append({
                        "food": food.strip(),
                        "reason": reason.strip()
                    })
                except ValueError:
                    continue

        return {
            "emotion": emotion,
            "intensity": intensity,
            "recommendations": recommendations
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
